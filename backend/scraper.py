import feedparser
import datetime
import time

# RSS ä¾†æºæ¸…å–®
RSS_FEEDS = [
    {
        "source": "The Verge",
        "url": "https://www.theverge.com/rss/index.xml",
        "category": "Tech"
    },
    {
        "source": "CoinDesk",
        "url": "https://www.coindesk.com/arc/outboundfeeds/rss/",
        "category": "Crypto"
    }
]

def get_today_news():
    """
    ä¸»å‡½å¼ï¼šæŠ“å–ä»Šæ—¥æ–°è (åš´æ ¼æ¨¡å¼)
    - æˆåŠŸï¼šå›å‚³æ–°èåˆ—è¡¨
    - å¤±æ•—ï¼šå›å‚³ç©ºåˆ—è¡¨ [] (çµ•å°ä¸å›å‚³å‡è³‡æ–™)
    """
    news_list = []
    print("ğŸ•·ï¸ [Scraper] é–‹å§‹æŠ“å–å¤–éƒ¨ RSS...")

    try:
        for feed_info in RSS_FEEDS:
            print(f"   - æ­£åœ¨è®€å–: {feed_info['source']}...")
            # è¨­å®š timeout é¿å…å¡æ­»
            # æ³¨æ„ï¼šfeedparser æœ¬èº«ä¸æ”¯æ´ timeout åƒæ•¸ï¼Œé€šå¸¸ä¾è³´ socket è¨­å®šï¼Œ
            # ä½†é€™è£¡æˆ‘å€‘ç°¡å–®è™•ç†ï¼Œè‹¥å¤±æ•—æœƒè¢« Exception æ•æ‰
            feed = feedparser.parse(feed_info['url'])
            
            if feed.bozo: # bozo=1 ä»£è¡¨è§£ææœ‰éŒ¯èª¤ (éæ¨™æº– XML æˆ–é€£ç·šå•é¡Œ)
                print(f"     âš ï¸ {feed_info['source']} è§£æè­¦å‘Š: {feed.bozo_exception}")
                continue

            # åªå–å‰ 5 ç¯‡ï¼Œé¿å…è³‡æ–™éèˆŠ
            for entry in feed.entries[:5]:
                # ç°¡å–®éæ¿¾ï¼šåªæŠ“ 24 å°æ™‚å…§çš„æ–°è (å¯é¸)
                # é€™è£¡å…ˆä¸åšæ™‚é–“éæ¿¾ï¼Œç¢ºä¿æœ‰è³‡æ–™å¯æ¸¬
                
                content = ""
                if 'content' in entry:
                    content = entry.content[0].value
                elif 'summary' in entry:
                    content = entry.summary
                else:
                    content = entry.title

                # ç°¡å–®æ¸…ç† HTML
                import re
                clean_content = re.sub('<[^<]+?>', '', content)[:1000]

                news_item = {
                    "title": entry.title,
                    "url": entry.link,
                    "content": clean_content,
                    "source": feed_info['source'],
                    "published_at": entry.get('published', datetime.datetime.now().isoformat()),
                    # é è¨­é¡åˆ¥ï¼Œç¨å¾Œ AI æœƒé‡æ–°åˆ†æ
                    "category": feed_info['category'] 
                }
                news_list.append(news_item)
                
            # ç¦®è²Œæ€§å»¶é²ï¼Œé¿å…è¢«æ“‹
            time.sleep(1)
        
        print(f"âœ… [Scraper] æˆåŠŸæŠ“å– {len(news_list)} ç¯‡çœŸå¯¦æ–°èã€‚")
        return news_list

    except Exception as e:
        print(f"âŒ [Scraper] ç™¼ç”Ÿåš´é‡éŒ¯èª¤: {e}")
        return [] # ç™¼ç”ŸéŒ¯èª¤ç›´æ¥å›å‚³ç©ºï¼Œä¸é€ å‡