#!/usr/bin/env python3
"""
æ¸¬è©¦ AI åˆ†æåŠŸèƒ½
"""

import sys
import os
sys.path.insert(0, os.path.dirname(__file__))

from ai_service import analyze_article
from cache_manager import get_cache_stats

print("ğŸ§ª æ¸¬è©¦ AI åˆ†æåŠŸèƒ½")
print("=" * 60)
print()

# æ¸¬è©¦æ–‡ç« 
test_article = """
OpenAI ç™¼å¸ƒäº†æœ€æ–°çš„ GPT-4 Turbo æ¨¡å‹ï¼Œåœ¨è™•ç†é€Ÿåº¦å’Œæˆæœ¬æ•ˆç›Šæ–¹é¢æœ‰é¡¯è‘—æå‡ã€‚
æ–°æ¨¡å‹è™•ç†é€Ÿåº¦æå‡2å€ï¼Œæˆæœ¬é™ä½50%ï¼Œä¸¦æ”¯æ´æ›´é•·çš„ä¸Šä¸‹æ–‡ã€‚
é€™å°‡åŠ é€Ÿä¼æ¥­æ¡ç”¨ AI æŠ€è¡“ï¼Œä¸¦ä¿ƒä½¿ç«¶çˆ­å°æ‰‹è·Ÿé€²ã€‚
"""

print("ğŸ“ æ¸¬è©¦æ–‡ç« å…§å®¹:")
print(test_article[:100] + "...")
print()

print("ğŸ¤– é–‹å§‹ AI åˆ†æ...")
result = analyze_article(
    text=test_article,
    title="OpenAI ç™¼å¸ƒ GPT-4 Turbo",
    source="Test Source",
    published_at="2025-12-26T10:00:00Z"
)

print()
print("=" * 60)

if result:
    print("âœ… AI åˆ†ææˆåŠŸï¼")
    print()
    print("ğŸ“Š åˆ†æçµæœ:")
    print(f"  - åˆ†é¡: {result.get('category', 'N/A')}")
    print(f"  - æ‘˜è¦: {result.get('summary', 'N/A')[:100]}...")
    print(f"  - ä¿¡å¿ƒåº¦: {result.get('confidence', 0.0):.2f}")
    print(f"  - æƒ…ç·’: {result.get('sentiment', 'N/A')}")
    print()
    
    # æª¢æŸ¥å¿«å–
    stats = get_cache_stats()
    print("ğŸ“Š å¿«å–çµ±è¨ˆ:")
    print(f"  - ç¸½æ•¸: {stats['total']}")
    print(f"  - æŒ‰é¡å‹: {stats['by_type']}")
else:
    print("âŒ AI åˆ†æå¤±æ•—")
    print()
    print("å¯èƒ½çš„åŸå› ï¼š")
    print("1. OPENAI_API_KEY æœªè¨­å®šæˆ–ç„¡æ•ˆ")
    print("2. ç¶²è·¯é€£ç·šå•é¡Œ")
    print("3. OpenAI API é…é¡ç”¨ç›¡")

