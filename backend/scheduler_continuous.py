"""
é•·æœŸé‹è¡Œçš„æ’ç¨‹å™¨ç‰ˆæœ¬
é©ç”¨æ–¼ Railwayã€Render ç­‰éœ€è¦æŒçºŒé‹è¡Œçš„å¹³å°
"""
import schedule
import time
import os
import json
import datetime
import firebase_admin
from firebase_admin import credentials, firestore
from dotenv import load_dotenv

# å¼•å…¥æ¨¡çµ„
from ai_service import analyze_article, analyze_category_group, generate_daily_briefing
from scraper import get_today_news
from collections import defaultdict

load_dotenv()

# ---------------------------------------------------------
# 1. åˆå§‹åŒ– Firebaseï¼ˆæ”¯æ´ç’°å¢ƒè®Šæ•¸æˆ–æª”æ¡ˆï¼‰
# ---------------------------------------------------------
if not firebase_admin._apps:
    # å„ªå…ˆå¾ç’°å¢ƒè®Šæ•¸è®€å–ï¼ˆé©ç”¨æ–¼ Railway Secretsï¼‰
    if os.getenv("SERVICE_ACCOUNT_KEY"):
        try:
            cred_dict = json.loads(os.getenv("SERVICE_ACCOUNT_KEY"))
            cred = credentials.Certificate(cred_dict)
            print("âœ… å¾ç’°å¢ƒè®Šæ•¸è¼‰å…¥ Firebase æœå‹™å¸³è™Ÿé‡‘é‘°")
        except json.JSONDecodeError:
            print("âŒ ç’°å¢ƒè®Šæ•¸ SERVICE_ACCOUNT_KEY æ ¼å¼éŒ¯èª¤")
            raise
    else:
        # å¾æª”æ¡ˆè®€å–ï¼ˆæœ¬åœ°é–‹ç™¼æˆ–å‚³çµ±éƒ¨ç½²ï¼‰
        CRED_PATH = os.path.join(os.path.dirname(__file__), "serviceAccountKey.json")
        if os.path.exists(CRED_PATH):
            cred = credentials.Certificate(CRED_PATH)
            print(f"âœ… å¾æª”æ¡ˆè¼‰å…¥ Firebase æœå‹™å¸³è™Ÿé‡‘é‘°: {CRED_PATH}")
        else:
            raise FileNotFoundError(
                "æ‰¾ä¸åˆ° serviceAccountKey.json ä¸”æœªè¨­å®š SERVICE_ACCOUNT_KEY ç’°å¢ƒè®Šæ•¸"
            )
    
    firebase_admin.initialize_app(cred)

db = firestore.client()

# ---------------------------------------------------------
# 2. ä¸»æµç¨‹
# ---------------------------------------------------------
def job_pipeline():
    today_str = datetime.datetime.now().strftime("%Y-%m-%d")
    print(f"ğŸš€ é–‹å§‹åŸ·è¡Œæ¯æ—¥ä»»å‹™ï¼š{today_str}")

    # A. ç²å–åŸæ–™ (éå»24å°æ™‚çš„æ–°è)
    raw_news_list = get_today_news()

    # ğŸ”¥ é—œéµæª¢æŸ¥ï¼šå¦‚æœæ²’æœ‰æ–°èï¼Œç›´æ¥çµ‚æ­¢
    if not raw_news_list:
        print("âš ï¸ è­¦å‘Šï¼šéå»24å°æ™‚å…§ç„¡æ³•æŠ“å–åˆ°ä»»ä½•æ–°è (æˆ–ä¾†æºç¶²ç«™æ›äº†)ã€‚")
        print("ğŸ›‘ ä»»å‹™çµ‚æ­¢ï¼Œæœªå¯«å…¥ä»»ä½•è³‡æ–™ï¼Œä»¥ç¢ºä¿ç„¡å¹»è¦ºã€‚")
        return

    # B. å–®ç¯‡åˆ†é¡åˆ†æ
    print(f"ğŸ§  [2/5] æ­£åœ¨åˆ†é¡ {len(raw_news_list)} ç¯‡æ–°è...")
    
    categorized_articles = defaultdict(list)
    
    for news in raw_news_list:
        # å‘¼å« AI åˆ†æç²å–åˆ†é¡ï¼ˆå‚³å…¥ metadataï¼‰
        analysis_result = analyze_article(
            text=news.get("content", ""),
            title=news.get("title", ""),
            source=news.get("source", ""),
            published_at=news.get("published_at", "")
        )
        
        if analysis_result:
            # åˆä½µ AI åˆ†æçµæœ
            processed_news = {**news, **analysis_result}
            category = analysis_result.get('category', 'æœªåˆ†é¡')
            categorized_articles[category].append(processed_news)
            confidence = analysis_result.get('confidence', 0.0)
            print(f"  - å·²åˆ†é¡: {news['title'][:30]}... -> {category} (ä¿¡å¿ƒåº¦: {confidence:.2f})")
        else:
            print(f"  - åˆ†æå¤±æ•—è·³é: {news['title'][:30]}...")

    if not categorized_articles:
        print("âŒ æ‰€æœ‰æ–°èåˆ†æçš†å¤±æ•—ï¼Œçµ‚æ­¢ä»»å‹™ã€‚")
        return

    # é™åˆ¶åˆ†é¡æ•¸é‡æœ€å¤š5å€‹ï¼ˆé¸æ“‡æ–‡ç« æ•¸æœ€å¤šçš„5å€‹åˆ†é¡ï¼‰
    if len(categorized_articles) > 5:
        print(f"âš ï¸ ç™¼ç¾ {len(categorized_articles)} å€‹åˆ†é¡ï¼Œå°‡ä¿ç•™æ–‡ç« æ•¸æœ€å¤šçš„5å€‹åˆ†é¡")
        sorted_categories = sorted(
            categorized_articles.items(), 
            key=lambda x: len(x[1]), 
            reverse=True
        )
        categorized_articles = dict(sorted_categories[:5])
        print(f"âœ… ä¿ç•™åˆ†é¡: {', '.join(categorized_articles.keys())}")

    # C. çµ±åˆåŒé¡æ–‡ç« ä¸¦åˆ†æ
    print(f"ğŸ“š [3/5] æ­£åœ¨çµ±åˆä¸¦åˆ†æ {len(categorized_articles)} å€‹åˆ†é¡...")
    category_analyses = []
    
    for category, articles in categorized_articles.items():
        print(f"  - åˆ†æåˆ†é¡ã€Œ{category}ã€({len(articles)}ç¯‡)...")
        category_analysis = analyze_category_group(category, articles)
        if category_analysis:
            category_analyses.append(category_analysis)
            print(f"    âœ… å®Œæˆ")
        else:
            print(f"    âŒ åˆ†æå¤±æ•—")

    if not category_analyses:
        print("âŒ æ‰€æœ‰åˆ†é¡åˆ†æçš†å¤±æ•—ï¼Œçµ‚æ­¢ä»»å‹™ã€‚")
        return

    # D. ç”Ÿæˆæ¯æ—¥æ±ºç­–æ—¥å ±
    print("ğŸ“ [4/5] æ­£åœ¨æ’°å¯«æ¯æ—¥æ±ºç­–æ—¥å ±...")
    daily_briefing_md = generate_daily_briefing(category_analyses)

    # E. å¯«å…¥ Firestore
    print("ğŸ’¾ [5/5] æ­£åœ¨å¯«å…¥è³‡æ–™åº«...")
    try:
        # è¨ˆç®—ç¸½æ–‡ç« æ•¸
        total_articles = sum(len(articles) for articles in categorized_articles.values())
        
        # æº–å‚™åˆ†é¡æ‘˜è¦è³‡æ–™ï¼ˆä½¿ç”¨å„ªåŒ–ç‰ˆçµæ§‹ï¼‰
        category_summaries = []
        for cat_analysis in category_analyses:
            category_summaries.append({
                'category': cat_analysis.get('category'),
                'article_count': cat_analysis.get('article_count', 0),
                'executive_summary': cat_analysis.get('executive_summary', cat_analysis.get('summary', '')),
                'storylines': cat_analysis.get('storylines', []),
                'key_points': cat_analysis.get('key_points', []),
                'risks': cat_analysis.get('risks', []),
                'opportunities': cat_analysis.get('opportunities', []),
                'signals_to_watch': cat_analysis.get('signals_to_watch', []),
                'confidence': cat_analysis.get('confidence', 0.0)
            })
        
        db.collection('daily_news').document(today_str).set({
            'date_str': today_str,
            'content': daily_briefing_md,
            'article_count': total_articles,
            'category_count': len(category_analyses),
            'categories': [cat.get('category') for cat in category_analyses],
            'category_summaries': category_summaries,  # æ–°å¢ï¼šåˆ†é¡æ‘˜è¦
            'created_at': firestore.SERVER_TIMESTAMP,
            'status': 'published'
        })
        
        print(f"âœ… ä»»å‹™æˆåŠŸï¼çœŸå¯¦æ—¥å ±å·²å­˜å…¥: daily_news/{today_str}")
        print(f"   ğŸ“Š çµ±è¨ˆ: {total_articles} ç¯‡æ–‡ç« ï¼Œ{len(category_analyses)} å€‹åˆ†é¡")

    except Exception as e:
        print(f"âŒ Firestore å¯«å…¥éŒ¯èª¤: {e}")

# ---------------------------------------------------------
# 3. æ’ç¨‹è¨­å®š
# ---------------------------------------------------------
# æ¯å¤© 09:00 UTC åŸ·è¡Œï¼ˆå¯æ ¹æ“šéœ€æ±‚èª¿æ•´ï¼‰
schedule.every().day.at("09:00").do(job_pipeline)

# ä¹Ÿå¯ä»¥è¨­å®šæ¯å°æ™‚åŸ·è¡Œï¼ˆæ¸¬è©¦ç”¨ï¼Œéƒ¨ç½²æ™‚è«‹ç§»é™¤ï¼‰
# schedule.every().hour.do(job_pipeline)

# ç«‹å³åŸ·è¡Œä¸€æ¬¡ï¼ˆå¯é¸ï¼Œç”¨æ–¼æ¸¬è©¦ï¼‰
# print("ğŸ§ª ç«‹å³åŸ·è¡Œä¸€æ¬¡æ¸¬è©¦...")
# job_pipeline()

if __name__ == "__main__":
    print("=" * 60)
    print("â° AI News Worker æ’ç¨‹å™¨å·²å•Ÿå‹•")
    print("=" * 60)
    print(f"ğŸ“… ä¸‹æ¬¡åŸ·è¡Œæ™‚é–“: {schedule.next_run()}")
    print(f"ğŸ”„ æª¢æŸ¥é–“éš”: æ¯ 60 ç§’")
    print("=" * 60)
    print("")
    
    # ä¸»å¾ªç’°
    while True:
        schedule.run_pending()
        time.sleep(60)  # æ¯åˆ†é˜æª¢æŸ¥ä¸€æ¬¡

