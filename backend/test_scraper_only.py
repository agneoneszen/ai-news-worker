#!/usr/bin/env python3
"""
æ¸¬è©¦ RSS æŠ“å–åŠŸèƒ½
"""

import sys
import os
sys.path.insert(0, os.path.dirname(__file__))

from scraper import get_today_news

print("ğŸ§ª æ¸¬è©¦ RSS æŠ“å–åŠŸèƒ½")
print("=" * 60)
print()

news_list = get_today_news()

print()
print("=" * 60)
print(f"ğŸ“Š çµæœ: å…±æŠ“å– {len(news_list)} ç¯‡æ–°è")
print("=" * 60)

if len(news_list) == 0:
    print()
    print("âš ï¸  æ²’æœ‰æŠ“å–åˆ°ä»»ä½•æ–°èï¼Œå¯èƒ½çš„åŸå› ï¼š")
    print("1. RSS ä¾†æºæ²’æœ‰éå»24å°æ™‚å…§çš„æ–°è")
    print("2. RSS ä¾†æºç„¡æ³•è¨ªå•")
    print("3. æ™‚é–“è§£æå¤±æ•—")
    print()
    print("å»ºè­°ï¼š")
    print("- æª¢æŸ¥ç¶²è·¯é€£ç·š")
    print("- æª¢æŸ¥ RSS ä¾†æºæ˜¯å¦æ­£å¸¸")
    print("- å¯ä»¥å˜—è©¦ä¿®æ”¹ scraper.py ä¸­çš„æ™‚é–“éæ¿¾æ¢ä»¶")
else:
    print()
    print("âœ… æˆåŠŸæŠ“å–æ–°èï¼Œå‰3ç¯‡æ¨™é¡Œï¼š")
    for i, news in enumerate(news_list[:3], 1):
        print(f"  {i}. {news.get('title', 'ç„¡æ¨™é¡Œ')[:60]}...")
        print(f"     ä¾†æº: {news.get('source', 'N/A')}")
        print(f"     æ™‚é–“: {news.get('published_at', 'N/A')}")

