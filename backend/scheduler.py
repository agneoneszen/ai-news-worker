import os
import datetime
import firebase_admin
from firebase_admin import credentials, firestore
from dotenv import load_dotenv
from concurrent.futures import ThreadPoolExecutor, as_completed

# å¼•å…¥æ¨¡çµ„
from ai_service import analyze_article, analyze_category_group, generate_daily_briefing
from scraper import get_today_news  # ä½¿ç”¨å‰›å‰›ä¿®æ”¹éçš„åš´æ ¼ç‰ˆçˆ¬èŸ²
from collections import defaultdict

load_dotenv()

# ---------------------------------------------------------
# 1. åˆå§‹åŒ– Firebase
# ---------------------------------------------------------
CRED_PATH = os.path.join(os.path.dirname(__file__), "serviceAccountKey.json")
if not firebase_admin._apps:
    cred = credentials.Certificate(CRED_PATH)
    firebase_admin.initialize_app(cred)

db = firestore.client()

# ---------------------------------------------------------
# 2. ä¸»æµç¨‹
# ---------------------------------------------------------
def job_pipeline():
    today_str = datetime.datetime.now().strftime("%Y-%m-%d")
    print(f"ğŸš€ é–‹å§‹åŸ·è¡Œæ¯æ—¥ä»»å‹™ï¼š{today_str}")

    # A. ç²å–åŸæ–™ (éå»24å°æ™‚çš„æ–°è)
    raw_news_list = get_today_news()

    # ğŸ”¥ é—œéµæª¢æŸ¥ï¼šå¦‚æœæ²’æœ‰æ–°èï¼Œç›´æ¥çµ‚æ­¢
    if not raw_news_list:
        print("âš ï¸ è­¦å‘Šï¼šéå»24å°æ™‚å…§ç„¡æ³•æŠ“å–åˆ°ä»»ä½•æ–°è (æˆ–ä¾†æºç¶²ç«™æ›äº†)ã€‚")
        print("ğŸ›‘ ä»»å‹™çµ‚æ­¢ï¼Œæœªå¯«å…¥ä»»ä½•è³‡æ–™ï¼Œä»¥ç¢ºä¿ç„¡å¹»è¦ºã€‚")
        return

    # B. å–®ç¯‡åˆ†é¡åˆ†æï¼ˆä¸¦è¡Œè™•ç†ä»¥æå‡æ•ˆç‡ï¼‰
    print(f"ğŸ§  [2/5] æ­£åœ¨åˆ†é¡ {len(raw_news_list)} ç¯‡æ–°èï¼ˆä¸¦è¡Œè™•ç†ï¼‰...")
    
    categorized_articles = defaultdict(list)
    
    # ä½¿ç”¨ä¸¦è¡Œè™•ç†åŠ é€Ÿåˆ†æï¼ˆæœ€å¤š 5 å€‹ä¸¦è¡Œï¼‰
    with ThreadPoolExecutor(max_workers=5) as executor:
        futures = {
            executor.submit(
                analyze_article,
                text=news.get("content", ""),
                title=news.get("title", ""),
                source=news.get("source", ""),
                published_at=news.get("published_at", "")
            ): news
            for news in raw_news_list
        }
        
        completed = 0
        for future in as_completed(futures):
            news = futures[future]
            completed += 1
            try:
                analysis_result = future.result()
                
                if analysis_result:
                    # åˆä½µ AI åˆ†æçµæœ
                    processed_news = {**news, **analysis_result}
                    category = analysis_result.get('category', 'æœªåˆ†é¡')
                    categorized_articles[category].append(processed_news)
                    confidence = analysis_result.get('confidence', 0.0)
                    print(f"  [{completed}/{len(raw_news_list)}] å·²åˆ†é¡: {news['title'][:30]}... -> {category} (ä¿¡å¿ƒåº¦: {confidence:.2f})")
                else:
                    print(f"  [{completed}/{len(raw_news_list)}] åˆ†æå¤±æ•—è·³é: {news['title'][:30]}...")
            except Exception as e:
                print(f"  [{completed}/{len(raw_news_list)}] åˆ†æç•°å¸¸: {news['title'][:30]}... - {e}")

    if not categorized_articles:
        print("âŒ æ‰€æœ‰æ–°èåˆ†æçš†å¤±æ•—ï¼Œçµ‚æ­¢ä»»å‹™ã€‚")
        return

    # é™åˆ¶åˆ†é¡æ•¸é‡æœ€å¤š5å€‹ï¼ˆé¸æ“‡æ–‡ç« æ•¸æœ€å¤šçš„5å€‹åˆ†é¡ï¼‰
    if len(categorized_articles) > 5:
        print(f"âš ï¸ ç™¼ç¾ {len(categorized_articles)} å€‹åˆ†é¡ï¼Œå°‡ä¿ç•™æ–‡ç« æ•¸æœ€å¤šçš„5å€‹åˆ†é¡")
        sorted_categories = sorted(
            categorized_articles.items(), 
            key=lambda x: len(x[1]), 
            reverse=True
        )
        categorized_articles = dict(sorted_categories[:5])
        print(f"âœ… ä¿ç•™åˆ†é¡: {', '.join(categorized_articles.keys())}")

    # C. çµ±åˆåŒé¡æ–‡ç« ä¸¦åˆ†æ
    print(f"ğŸ“š [3/5] æ­£åœ¨çµ±åˆä¸¦åˆ†æ {len(categorized_articles)} å€‹åˆ†é¡...")
    category_analyses = []
    
    for category, articles in categorized_articles.items():
        print(f"  - åˆ†æåˆ†é¡ã€Œ{category}ã€({len(articles)}ç¯‡)...")
        category_analysis = analyze_category_group(category, articles)
        if category_analysis:
            category_analyses.append(category_analysis)
            print(f"    âœ… å®Œæˆ")
        else:
            print(f"    âŒ åˆ†æå¤±æ•—")

    if not category_analyses:
        print("âŒ æ‰€æœ‰åˆ†é¡åˆ†æçš†å¤±æ•—ï¼Œçµ‚æ­¢ä»»å‹™ã€‚")
        return

    # D. ç”Ÿæˆæ¯æ—¥æ±ºç­–æ—¥å ±ï¼ˆå‚³éåŸå§‹æ–‡ç« åˆ—è¡¨ä»¥åŒ…å«ä¾†æºé€£çµï¼‰
    print("ğŸ“ [4/5] æ­£åœ¨æ’°å¯«æ¯æ—¥æ±ºç­–æ—¥å ±...")
    # æ”¶é›†æ‰€æœ‰å·²è™•ç†çš„æ–‡ç« ï¼ˆåŒ…å« URLï¼‰
    all_processed_articles = []
    for articles in categorized_articles.values():
        all_processed_articles.extend(articles)
    daily_briefing_md = generate_daily_briefing(category_analyses, source_articles=all_processed_articles)

    # E. å¯«å…¥ Firestore
    print("ğŸ’¾ [5/5] æ­£åœ¨å¯«å…¥è³‡æ–™åº«...")
    try:
        # è¨ˆç®—ç¸½æ–‡ç« æ•¸
        total_articles = sum(len(articles) for articles in categorized_articles.values())
        
        # æº–å‚™åˆ†é¡æ‘˜è¦è³‡æ–™ï¼ˆä½¿ç”¨å„ªåŒ–ç‰ˆçµæ§‹ï¼‰
        category_summaries = []
        for cat_analysis in category_analyses:
            category_summaries.append({
                'category': cat_analysis.get('category'),
                'article_count': cat_analysis.get('article_count', 0),
                'executive_summary': cat_analysis.get('executive_summary', cat_analysis.get('summary', '')),
                'storylines': cat_analysis.get('storylines', []),
                'key_points': cat_analysis.get('key_points', []),
                'risks': cat_analysis.get('risks', []),
                'opportunities': cat_analysis.get('opportunities', []),
                'signals_to_watch': cat_analysis.get('signals_to_watch', []),
                'confidence': cat_analysis.get('confidence', 0.0)
            })
        
        # æº–å‚™å¯«å…¥è³‡æ–™
        doc_data = {
            'date_str': today_str,
            'content': daily_briefing_md,
            'article_count': total_articles,
            'category_count': len(category_analyses),
            'categories': [cat.get('category') for cat in category_analyses],
            'category_summaries': category_summaries,  # æ–°å¢ï¼šåˆ†é¡æ‘˜è¦
            'created_at': firestore.SERVER_TIMESTAMP,
            'status': 'published'
        }
        
        print(f"ğŸ’¾ æº–å‚™å¯«å…¥è³‡æ–™åˆ°: daily_news/{today_str}")
        print(f"   - å…§å®¹é•·åº¦: {len(daily_briefing_md)} å­—å…ƒ")
        print(f"   - æ–‡ç« æ•¸: {total_articles}")
        print(f"   - åˆ†é¡æ•¸: {len(category_analyses)}")
        
        # å¯«å…¥ Firestore
        doc_ref = db.collection('daily_news').document(today_str)
        doc_ref.set(doc_data)
        
        # é©—è­‰å¯«å…¥
        verify_doc = doc_ref.get()
        if verify_doc.exists:
            print(f"âœ… ä»»å‹™æˆåŠŸï¼çœŸå¯¦æ—¥å ±å·²å­˜å…¥: daily_news/{today_str}")
            print(f"   ğŸ“Š çµ±è¨ˆ: {total_articles} ç¯‡æ–‡ç« ï¼Œ{len(category_analyses)} å€‹åˆ†é¡")
            print(f"   âœ… Firestore å¯«å…¥é©—è­‰æˆåŠŸ")
        else:
            print(f"âš ï¸  è­¦å‘Š: å¯«å…¥å¾Œé©—è­‰å¤±æ•—ï¼Œè«‹æª¢æŸ¥ Firestore æ¬Šé™")

    except Exception as e:
        print(f"âŒ Firestore å¯«å…¥éŒ¯èª¤: {e}")

if __name__ == "__main__":
    job_pipeline()