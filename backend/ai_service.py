import os
import json
from openai import OpenAI
from dotenv import load_dotenv
from cache_manager import (
    get_content_hash, 
    get_cached_result, 
    save_cached_result,
    clear_expired_cache
)

load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# å•Ÿå‹•æ™‚æ¸…é™¤éæœŸå¿«å–
clear_expired_cache()

def analyze_article(text, title="", source="", published_at=""):
    """
    åˆ†æå–®ç¯‡æ–‡ç« ï¼Œå›å‚³å„ªåŒ–ç‰ˆ JSON çµæ§‹ï¼ˆå¸¶è­‰æ“šã€å¯æ±ºç­–ï¼‰
    ä½¿ç”¨å¿«å–é¿å…é‡è¤‡åˆ†æç›¸åŒå…§å®¹
    
    Args:
        text: æ–°èå…§å®¹
        title: æ–°èæ¨™é¡Œï¼ˆå¯é¸ï¼‰
        source: æ–°èä¾†æºï¼ˆå¯é¸ï¼‰
        published_at: ç™¼å¸ƒæ™‚é–“ ISO 8601ï¼ˆå¯é¸ï¼‰
    
    Returns:
        JSON çµæ§‹åŒ…å«ï¼šsummary, highlights, category, entities, sentiment, 
        time_horizon, impact_scope, why_it_matters, insight, 
        action_suggestions, confidence, uncertainties
    """
    if not text: 
        return None
    
    # æª¢æŸ¥å¿«å–
    metadata = {'title': title, 'source': source}
    cache_key = get_content_hash(text, metadata)
    cached_result = get_cached_result(cache_key, cache_type="article")
    
    if cached_result:
        return cached_result
    
    # é¿å… Token çˆ†é‡ï¼Œæˆªå–å‰ 2500 å­—
    input_text = text[:2500]
    
    system_prompt = """# Role
ä½ æ˜¯ä¸€ä½ã€Œç¹é«”ä¸­æ–‡ã€çš„è³‡æ·±ç§‘æŠ€/åŠ å¯†ç”¢æ¥­åˆ†æå¸«ï¼Œæ“…é•·å°‡æ–°èè½‰æˆå¯åŸ·è¡Œçš„æ±ºç­–è³‡è¨Šã€‚

# Core Rules (Very Important)
1) åƒ…èƒ½æ ¹æ“šã€æ–°èå…§å®¹ã€‘æ¨è«–ï¼Œä¸å¾—æœæ’¬ã€ä¸å¾—ç·¨é€ ä¸å­˜åœ¨çš„æ•¸å­—/äººå/äº‹ä»¶ã€‚
2) å¦‚å…§å®¹ä¸è¶³ä»¥æ”¯æŒçµè«–ï¼Œè«‹æ˜ç¢ºå¯«ã€Œè³‡è¨Šä¸è¶³ã€ä¸¦é™ä½ confidenceã€‚
3) æ‰€æœ‰é‡é»å¿…é ˆé™„ä¸Š evidenceï¼šç”¨ã€ŒåŸæ–‡ç‰‡æ®µã€æˆ–ã€Œé—œéµå¥ã€(<=25å­—) ä½œç‚ºä½è­‰ã€‚
4) è¼¸å‡ºå¿…é ˆæ˜¯ã€Œå–®ä¸€ JSONã€ï¼Œä¸å¯åŒ…å« Markdownã€ä¸å¯åŒ…å«å¤šé¤˜æ–‡å­—ã€ä¸å¯åŠ è¨»è§£ã€‚
5) åˆ†é¡è«‹ä½¿ç”¨æ—¢å®šé¡åˆ¥ï¼Œä¸ç¬¦åˆæ‰è‡ªè¨‚ï¼šäººå·¥æ™ºæ…§ã€å€å¡Šéˆã€ç¡¬é«”ã€å•†æ¥­ã€è³‡å®‰ã€æ”¿ç­–æ³•è¦ã€å®è§€ç¶“æ¿Ÿã€å…¶ä»–ã€‚

# Task
é–±è®€ã€æ–°èå…§å®¹ã€‘ï¼Œå›å‚³ä¸‹åˆ— JSONï¼ˆæ¬„ä½ä¸å¯ç¼ºæ¼ï¼‰ï¼š
{
  "title": "è‹¥åŸæ–‡å«æ¨™é¡Œå‰‡å¡«ï¼Œå¦å‰‡ç©ºå­—ä¸²",
  "source": "è‹¥åŸæ–‡å«ä¾†æº/åª’é«”å‰‡å¡«ï¼Œå¦å‰‡ç©ºå­—ä¸²",
  "published_at": "è‹¥åŸæ–‡å«æ—¥æœŸæ™‚é–“(ISO 8601å„ªå…ˆ)å‰‡å¡«ï¼Œå¦å‰‡ç©ºå­—ä¸²",
  "language": "zh/ja/en/otherï¼ˆä¾å…§å®¹åˆ¤æ–·ï¼‰",

  "summary": "æ•˜è¿°æ€§æ‘˜è¦(ç¹é«”ä¸­æ–‡ï¼Œ80-120å­—ï¼Œå«ä¸»è©/äº‹ä»¶/å½±éŸ¿)",
  "highlights": [
    {"point": "é‡é»1(<=26å­—)", "evidence": "ä½è­‰ç‰‡æ®µ(<=25å­—)"},
    {"point": "é‡é»2(<=26å­—)", "evidence": "ä½è­‰ç‰‡æ®µ(<=25å­—)"},
    {"point": "é‡é»3(<=26å­—)", "evidence": "ä½è­‰ç‰‡æ®µ(<=25å­—)"}
  ],

  "category": "åˆ†é¡",
  "tags": ["3-8å€‹æ¨™ç±¤(ç¹ä¸­ï¼Œé¿å…é‡è¤‡)"],

  "entities": {
    "companies": ["å…¬å¸/çµ„ç¹”"],
    "people": ["äººç‰©"],
    "products": ["ç”¢å“/å”è­°/æ¨¡å‹/éˆ"],
    "tickers": ["BTC","ETH","SOL"... è‹¥ç„¡å‰‡[]],
    "locations": ["åœ°é»/åœ‹å®¶å€åŸŸ"]
  },

  "sentiment": "bullish/bearish/neutral/mixedï¼ˆé‡å°è©²æ–°èå°ç”¢æ¥­æˆ–å¸‚å ´çš„å‚¾å‘ï¼‰",
  "time_horizon": "now/1w/1m/1q/1yï¼ˆä¸»è¦å½±éŸ¿æ™‚é–“å°ºåº¦ï¼‰",
  "impact_scope": ["æŠ•è³‡å¸‚å ´","é–‹ç™¼è€…","ä¼æ¥­æ¡ç”¨","ç›£ç®¡","å®‰å…¨é¢¨éšª","ä¾›æ‡‰éˆ","å…¶ä»–"],
  "why_it_matters": "ä¸€å¥è©±ï¼šé€™å‰‡æ–°èå°æ±ºç­–è€…/æŠ•è³‡è€…/é–‹ç™¼è€…çš„é‡è¦æ€§(<=40å­—)",

  "insight": "ä¸€å¥è©±ç”¢æ¥­æ´å¯Ÿï¼ˆåçµæ§‹æ€§ã€é¿å…ç©ºæ³›ï¼‰",

  "action_suggestions": [
    "çµ¦ç”¢å“/å·¥ç¨‹/æŠ•è³‡/ç‡Ÿé‹å¯åšçš„ä¸‹ä¸€æ­¥ï¼ˆæœ€å¤š3æ¢ã€æ¯æ¢<=18å­—ã€å¯ç‚º'å…ˆè§€å¯Ÿ'ï¼‰"
  ],

  "confidence": 0.0,
  "uncertainties": ["ä¸ç¢ºå®šé»/ç¼ºå°‘è³‡è¨Šï¼ˆæœ€å¤š3æ¢ï¼‰"]
}

# Confidence Scoring Guide
- 0.8~1.0ï¼šè³‡è¨Šå®Œæ•´ä¸”æœ‰æ˜ç¢ºä½è­‰
- 0.5~0.7ï¼šé—œéµè³‡è¨Šé½Šä½†ä»æœ‰ç¼ºå£
- 0.2~0.4ï¼šè³‡è¨Šç‰‡æ®µåŒ–ï¼Œåªèƒ½åšä¿å®ˆæ‘˜è¦
- 0.0~0.1ï¼šå…§å®¹ä¸æ§‹æˆæœ‰æ•ˆæ–°è/å¤ªçŸ­/ç„¡æ³•åˆ¤æ–·"""
    
    # æ§‹å»ºç”¨æˆ¶è¼¸å…¥ï¼ŒåŒ…å«å¯ç”¨çš„ metadata
    user_content = input_text
    if title or source or published_at:
        metadata_parts = []
        if title:
            metadata_parts.append(f"æ¨™é¡Œï¼š{title}")
        if source:
            metadata_parts.append(f"ä¾†æºï¼š{source}")
        if published_at:
            metadata_parts.append(f"ç™¼å¸ƒæ™‚é–“ï¼š{published_at}")
        user_content = "\n".join(metadata_parts) + "\n\n" + input_text
    
    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_content}
            ],
            temperature=0.25,  # å„ªåŒ–ï¼š0.2~0.3ï¼Œä½¿ç”¨ 0.25
            response_format={"type": "json_object"}
        )
        result = json.loads(response.choices[0].message.content)
        
        # å„²å­˜åˆ°å¿«å–
        save_cached_result(
            cache_key, 
            result, 
            cache_type="article",
            metadata={'title': title, 'source': source, 'published_at': published_at}
        )
        
        return result
    except Exception as e:
        print(f"âŒ AI åˆ†æå¤±æ•—: {e}")
        return None

def analyze_category_group(category_name, articles_in_category):
    """
    åˆ†æåŒä¸€åˆ†é¡çš„å¤šç¯‡æ–‡ç« ï¼Œç”Ÿæˆçµ±åˆåˆ†æï¼ˆå„ªåŒ–ç‰ˆï¼šå»é‡ã€æŠ½ä¸»ç·šã€ç”¢å‡ºå¯è¿½è¹¤ä¿¡è™Ÿï¼‰
    ä½¿ç”¨å¿«å–é¿å…é‡è¤‡åˆ†æç›¸åŒåˆ†é¡çµ„åˆ
    
    Args:
        category_name: åˆ†é¡åç¨±
        articles_in_category: è©²åˆ†é¡ä¸‹çš„æ–‡ç« åˆ—è¡¨ï¼ˆæ‡‰åŒ…å« analyze_article çš„å®Œæ•´çµæœï¼‰
    
    Returns:
        JSON çµæ§‹åŒ…å«ï¼šexecutive_summary, storylines, key_points, trend_analysis,
        risks, opportunities, signals_to_watch, confidence, uncertainties
    """
    if not articles_in_category:
        return None
    
    # æª¢æŸ¥å¿«å–ï¼ˆåŸºæ–¼åˆ†é¡åç¨±å’Œæ–‡ç« æ¨™é¡Œçµ„åˆï¼‰
    article_titles = [art.get('title', '') for art in articles_in_category]
    cache_content = f"{category_name}:{','.join(sorted(article_titles))}"
    cache_key = get_content_hash(cache_content)
    cached_result = get_cached_result(cache_key, cache_type="category")
    
    if cached_result:
        # æ›´æ–° article_count å’Œ article_titlesï¼ˆå¯èƒ½ä¸åŒï¼‰
        cached_result['article_count'] = len(articles_in_category)
        cached_result['article_titles'] = article_titles
        return cached_result
    
    # æº–å‚™æ–‡ç« è³‡æ–™ï¼ˆä½¿ç”¨çµæ§‹åŒ–çµæœè€ŒéåŸå§‹å…§å®¹ï¼‰
    article_data = []
    article_titles = []
    
    for article in articles_in_category:
        title = article.get('title', 'ç„¡æ¨™é¡Œ')
        article_titles.append(title)
        
        # å„ªå…ˆä½¿ç”¨çµæ§‹åŒ–åˆ†æçµæœ
        summary = article.get('summary', '')
        highlights = article.get('highlights', [])
        insight = article.get('insight', '')
        entities = article.get('entities', {})
        sentiment = article.get('sentiment', 'neutral')
        why_it_matters = article.get('why_it_matters', '')
        
        # å¦‚æœæ²’æœ‰çµæ§‹åŒ–çµæœï¼Œä½¿ç”¨åŸå§‹å…§å®¹
        if not summary:
            summary = article.get('content', '')[:500]
        
        article_data.append({
            'title': title,
            'summary': summary,
            'highlights': highlights,
            'insight': insight,
            'entities': entities,
            'sentiment': sentiment,
            'why_it_matters': why_it_matters
        })
    
    # æ§‹å»ºè¼¸å…¥å…§å®¹ï¼ˆä½¿ç”¨çµæ§‹åŒ–è³‡æ–™ï¼Œæ›´çœ tokenï¼Œé€²ä¸€æ­¥å„ªåŒ–ï¼‰
    combined_input = ""
    for art in article_data:
        combined_input += f"\nã€{art['title']}ã€‘\n"
        # é™åˆ¶æ‘˜è¦é•·åº¦ä»¥ç¯€çœ token
        summary = art['summary'][:200] if len(art['summary']) > 200 else art['summary']
        combined_input += f"æ‘˜è¦ï¼š{summary}\n"
        
        # åªå–å‰ 2 å€‹é‡é»
        if art.get('highlights'):
            if isinstance(art['highlights'], list) and len(art['highlights']) > 0:
                if isinstance(art['highlights'][0], dict):
                    highlights_str = "; ".join([h.get('point', '') for h in art['highlights'][:2]])
                else:
                    highlights_str = "; ".join(art['highlights'][:2])
                combined_input += f"é‡é»ï¼š{highlights_str}\n"
        
        # åªå‚³éé—œéµè³‡è¨Š
        combined_input += f"æ´å¯Ÿï¼š{art.get('insight', '')[:80]}\n"  # é™åˆ¶æ´å¯Ÿé•·åº¦
        combined_input += f"é‡è¦æ€§ï¼š{art.get('why_it_matters', '')}\n"
        combined_input += f"æƒ…ç·’ï¼š{art.get('sentiment', 'neutral')}\n"
    
    # é™åˆ¶ç¸½é•·åº¦
    if len(combined_input) > 8000:
        combined_input = combined_input[:8000] + "..."
    
    system_prompt = """ä½ æ˜¯ä¸€ä½ç¹é«”ä¸­æ–‡çš„è³‡æ·±ç§‘æŠ€/åŠ å¯†ç”¢æ¥­åˆ†æå¸«ï¼Œæ“…é•·æŠŠå¤šç¯‡æ–°èã€Œå»é‡ã€æŠ“ä¸»ç·šã€åšæƒ…å¢ƒæ¨æ¼”ã€ã€‚

# Rules
1) åƒ…èƒ½ä½¿ç”¨è¼¸å…¥æ–‡ç« å…§å®¹ï¼›ä¸å¯å¼•å…¥å¤–éƒ¨èƒŒæ™¯çŸ¥è­˜ç•¶ä½œäº‹å¯¦ã€‚
2) éœ€è¦ã€Œå»é‡ã€ï¼šç›¸åŒäº‹ä»¶è«‹åˆä½µæè¿°ï¼Œä¸è¦é‡è¤‡åˆ—é»ã€‚
3) è‹¥åŒåˆ†é¡å…§å‡ºç¾çŸ›ç›¾èªªæ³•ï¼Œå¿…é ˆæŒ‡å‡ºä¸¦æ¨™è¨˜ uncertaintiesã€‚
4) æ¯å€‹ key_point èˆ‡ signal å¿…é ˆèƒ½è¿½æº¯åˆ°è‡³å°‘ä¸€ç¯‡æ–‡ç« æ¨™é¡Œï¼ˆç”¨ titles å¼•ç”¨å³å¯ï¼Œä¸è¦è²¼é•·æ–‡ï¼‰ã€‚
5) è¼¸å‡ºå¿…é ˆæ˜¯å–®ä¸€ JSONï¼Œä¸è¦ Markdownã€‚

# Task
åˆ†æåŒä¸€åˆ†é¡çš„å¤šç¯‡æ–‡ç« ï¼Œå›å‚³ï¼š
{
  "category": "åˆ†é¡åç¨±ï¼ˆèˆ‡è¼¸å…¥ç›¸åŒï¼‰",
  "executive_summary": "çµ±åˆæ‘˜è¦ï¼ˆ200-280å­—ï¼Œç¹é«”ä¸­æ–‡ï¼Œå…ˆçµè«–å¾Œç†ç”±ï¼‰",

  "storylines": [
    {
      "theme": "ä¸»ç·šæ¨™é¡Œ(<=18å­—)",
      "what_happened": "ç™¼ç”Ÿä»€éº¼(<=60å­—)",
      "why_it_matters": "é‡è¦æ€§(<=60å­—)",
      "who_is_affected": ["æŠ•è³‡è€…","é–‹ç™¼è€…","äº¤æ˜“æ‰€","ä¼æ¥­","ç›£ç®¡æ–¹","ç”¨æˆ¶","å…¶ä»–"],
      "time_horizon": "now/1w/1m/1q/1y",
      "titles": ["æ”¯æ’æ­¤ä¸»ç·šçš„æ–‡ç« æ¨™é¡Œ1","æ¨™é¡Œ2"]
    }
  ],

  "key_points": [
    {"point":"é‡é»(<=26å­—)","titles":["æ¨™é¡Œ1"]},
    {"point":"é‡é»(<=26å­—)","titles":["æ¨™é¡Œ2"]}
  ],

  "trend_analysis": "è¶¨å‹¢åˆ†æèˆ‡ç”¢æ¥­å½±éŸ¿ï¼ˆ150-220å­—ï¼Œç¹é«”ä¸­æ–‡ï¼›é¿å…å£è™Ÿï¼‰",

  "risks": [
    {"risk":"é¢¨éšª(<=22å­—)","type":"regulatory/security/market/tech/ops/other","titles":["æ¨™é¡Œ1"]}
  ],

  "opportunities": [
    {"opp":"æ©Ÿæœƒ(<=22å­—)","titles":["æ¨™é¡Œ1"]}
  ],

  "signals_to_watch": [
    {"signal":"å¯è§€æ¸¬ä¿¡è™Ÿ(<=22å­—)","how_to_track":"ç”¨ä»€éº¼æŒ‡æ¨™/äº‹ä»¶è¿½(<=24å­—)","expected_direction":"up/down/unknown"}
  ],

  "confidence": 0.0,
  "uncertainties": ["è³‡æ–™ç¼ºå£/çŸ›ç›¾é»ï¼ˆæœ€å¤š4æ¢ï¼‰"]
}"""
    
    user_content = f"""åˆ†é¡ï¼š{category_name}
æ–‡ç« æ•¸é‡ï¼š{len(articles_in_category)}
æ–‡ç« æ¨™é¡Œï¼š{', '.join(article_titles[:10])}

æ–‡ç« å…§å®¹ï¼š
{combined_input}
"""
    
    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_content}
            ],
            temperature=0.35,  # å„ªåŒ–ï¼š0.3~0.4ï¼Œä½¿ç”¨ 0.35
            response_format={"type": "json_object"}
        )
        result = json.loads(response.choices[0].message.content)
        result['article_count'] = len(articles_in_category)
        result['article_titles'] = article_titles
        
        # å„²å­˜åˆ°å¿«å–
        save_cached_result(
            cache_key,
            result,
            cache_type="category",
            metadata={'category': category_name, 'article_count': len(articles_in_category)}
        )
        
        return result
    except Exception as e:
        print(f"âŒ åˆ†é¡åˆ†æå¤±æ•— ({category_name}): {e}")
        return None

def generate_daily_briefing(category_analyses):
    """
    æ ¹æ“šåˆ†é¡åˆ†æçµæœç”Ÿæˆæ¯æ—¥æ±ºç­–æ—¥å ±ï¼ˆå„ªåŒ–ç‰ˆï¼šæ›´è²¼è¿‘æŠ•è³‡/ç”¢å“/é¢¨æ§/è¡Œå‹•æ¸…å–®ï¼‰
    
    Args:
        category_analyses: åˆ†é¡åˆ†æçµæœåˆ—è¡¨ï¼ˆæ‡‰åŒ…å« analyze_category_group çš„å®Œæ•´çµæœï¼‰
    
    Returns:
        Markdown æ ¼å¼çš„æ±ºç­–æ—¥å ±
    """
    if not category_analyses:
        return "âš ï¸ è³‡æ–™ä¸è¶³ï¼Œç„¡æ³•ç”Ÿæˆæ—¥å ±ã€‚"

    # æ•´ç†è³‡æ–™çµ¦ AIï¼ˆä½¿ç”¨çµæ§‹åŒ–çµæœï¼‰
    input_text = ""
    for cat_analysis in category_analyses:
        category = cat_analysis.get('category', 'æœªåˆ†é¡')
        executive_summary = cat_analysis.get('executive_summary', cat_analysis.get('summary', ''))
        storylines = cat_analysis.get('storylines', [])
        key_points = cat_analysis.get('key_points', [])
        trend_analysis = cat_analysis.get('trend_analysis', '')
        risks = cat_analysis.get('risks', [])
        opportunities = cat_analysis.get('opportunities', [])
        signals_to_watch = cat_analysis.get('signals_to_watch', [])
        confidence = cat_analysis.get('confidence', 0.0)
        uncertainties = cat_analysis.get('uncertainties', [])
        article_count = cat_analysis.get('article_count', 0)
        
        input_text += f"\n## {category} ({article_count}ç¯‡)\n"
        input_text += f"æ‘˜è¦ï¼š{executive_summary}\n"
        
        if storylines:
            input_text += f"ä¸»ç·šï¼š{len(storylines)}æ¢\n"
            for sl in storylines[:2]:  # æœ€å¤šé¡¯ç¤º2æ¢ä¸»ç·š
                input_text += f"  - {sl.get('theme', '')}: {sl.get('what_happened', '')}\n"
        
        if key_points:
            if isinstance(key_points[0], dict):
                points_str = "; ".join([kp.get('point', '') for kp in key_points[:3]])
            else:
                points_str = "; ".join(key_points[:3])
            input_text += f"é‡é»ï¼š{points_str}\n"
        
        input_text += f"è¶¨å‹¢ï¼š{trend_analysis}\n"
        
        if risks:
            risks_str = "; ".join([r.get('risk', '') if isinstance(r, dict) else r for r in risks[:2]])
            input_text += f"é¢¨éšªï¼š{risks_str}\n"
        
        if opportunities:
            opps_str = "; ".join([o.get('opp', '') if isinstance(o, dict) else o for o in opportunities[:2]])
            input_text += f"æ©Ÿæœƒï¼š{opps_str}\n"
        
        if signals_to_watch:
            signals_str = "; ".join([s.get('signal', '') if isinstance(s, dict) else s for s in signals_to_watch[:3]])
            input_text += f"ä¿¡è™Ÿï¼š{signals_str}\n"
        
        input_text += f"ä¿¡å¿ƒåº¦ï¼š{confidence}\n"
        if uncertainties:
            input_text += f"ä¸ç¢ºå®šæ€§ï¼š{'; '.join(uncertainties[:2])}\n"
    
    if len(input_text) > 6000: 
        input_text = input_text[:6000] + "..."

    system_prompt = """ä½ æ˜¯ä¸€ä½åŠ å¯†è²¨å¹£èˆ‡ç§‘æŠ€ç”¢æ¥­çš„ã€Œé¦–å¸­ç­–ç•¥å®˜ï¼ˆCSOï¼‰ã€ï¼Œè¼¸å‡ºç›®æ¨™æ˜¯ï¼šè®“è®€è€…åœ¨ 3 åˆ†é˜å…§å®Œæˆä»Šæ—¥æ±ºç­–æ’åºã€‚

# Rules
1) åƒ…èƒ½ä½¿ç”¨è¼¸å…¥çš„ã€åˆ†é¡åˆ†æçµæœã€‘ï¼›ä¸å¯æ–°å¢å¤–éƒ¨äº‹å¯¦æˆ–æ•¸å­—ã€‚
2) å…ˆçµ¦çµè«–ï¼Œå†çµ¦ç†ç”±ï¼›é¿å…ç©ºè©±èˆ‡å£è™Ÿã€‚
3) æ¯æ®µçµè«–ç›¡é‡è½åˆ°ã€Œè¡Œå‹• / è§€å¯Ÿä¿¡è™Ÿ / é¢¨éšªé‚Šç•Œã€ã€‚
4) å…§å®¹ä»¥ç¹é«”ä¸­æ–‡ç‚ºä¸»ï¼Œå°ˆæœ‰åè©å¯ä¿ç•™è‹±æ–‡ã€‚

# Output: Markdown structure (must follow)
1) ä»Šæ—¥ä¸‰å¥è©±ï¼ˆTL;DRï¼‰
2) ğŸ“Š å¸‚å ´æƒ…ç·’å„€è¡¨æ¿ï¼ˆæƒ…ç·’ã€ç†±è©ã€è³‡é‡‘/ç›£ç®¡/è³‡å®‰ä¸»å°å› å­ï¼‰
3) ğŸŒŠ æ ¸å¿ƒè¶¨å‹¢åˆ†æï¼ˆ3-5æ¢ storylinesï¼›æ¯æ¢å«ï¼šå½±éŸ¿ã€æ™‚é–“å°ºåº¦ã€è¦è¿½çš„ä¿¡è™Ÿï¼‰
4) ğŸ§­ æ±ºç­–æŒ‡å¼•ï¼ˆåˆ†æˆï¼šæŠ•è³‡/äº¤æ˜“ã€ç”¢å“/å·¥ç¨‹ã€ç‡Ÿé‹/é¢¨æ§ï¼›æ¯æ®µ 3-6 bulletsï¼‰
5) ğŸ”­ ä»Šæ—¥ç›£æ¸¬æ¸…å–®ï¼ˆ5-10å€‹ signals_to_watchï¼Œåšæˆ checklistï¼‰
6) ğŸ“ˆ åˆ†é¡æ‘˜è¦ï¼ˆæ¯åˆ†é¡ 3 bulletsï¼›é™„ confidenceï¼‰
7) ğŸ§± ä¸ç¢ºå®šæ€§èˆ‡åæ–¹è§€é»ï¼ˆåˆ— 3-6 é»ï¼Œé¿å…å–®é‚Šï¼‰

# Style constraints
- ç”¨çŸ­å¥ã€çŸ­æ®µè½ã€è¦é»åŒ–ã€‚
- Bullet ä»¥ã€Œå¯åŸ·è¡Œã€ç‚ºå„ªå…ˆï¼šå‹•è©é–‹é ­ï¼ˆè¿½è¹¤/æš«åœ/è©•ä¼°/å°æ²–/ç¢ºèªâ€¦ï¼‰ã€‚"""

    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": f"ã€åˆ†é¡åˆ†æçµæœã€‘\n{input_text}"}
            ],
            temperature=0.55,  # å„ªåŒ–ï¼š0.5~0.6ï¼Œä½¿ç”¨ 0.55
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        return f"âš ï¸ å ±å‘Šç”Ÿæˆå¤±æ•—: {e}"
