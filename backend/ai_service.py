import os
import json
from openai import OpenAI
from dotenv import load_dotenv

load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

def analyze_article(text):
    """åˆ†æå–®ç¯‡æ–‡ç« ï¼Œå›å‚³ JSON çµæ§‹"""
    if not text: return None
    # é¿å… Token çˆ†é‡ï¼Œæˆªå–å‰ 2500 å­—
    input_text = text[:2500]
    
    system_prompt = """
# Role
ä½ æ˜¯ä¸€ä½ç¹é«”ä¸­æ–‡çš„è³‡æ·±ç§‘æŠ€ç”¢æ¥­åˆ†æå¸«ã€‚

# Task
é–±è®€ã€æ–°èå…§å®¹ã€‘ï¼Œå›å‚³ä»¥ä¸‹ JSON æ ¼å¼ï¼š
{
  "summary": "æ•˜è¿°æ€§æ‘˜è¦(ç¹é«”ä¸­æ–‡)",
  "highlights": "<li><b>é‡é»1ï¼š</b>å…§å®¹</li><li><b>é‡é»2ï¼š</b>å…§å®¹</li><li><b>é‡é»3ï¼š</b>å…§å®¹</li>",
  "category": "åˆ†é¡(å¦‚:äººå·¥æ™ºæ…§,å€å¡Šéˆ,ç¡¬é«”,å•†æ¥­,è³‡å®‰,æˆ–è‡ªè¨‚)",
  "insight": "ä¸€å¥è©±ç”¢æ¥­æ·±åº¦æ´å¯Ÿ"
}
"""
    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini", # æˆ– gpt-3.5-turbo
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": input_text}
            ],
            temperature=0.3,
            response_format={"type": "json_object"}
        )
        return json.loads(response.choices[0].message.content)
    except Exception as e:
        print(f"âŒ AI åˆ†æå¤±æ•—: {e}")
        return None

def analyze_category_group(category_name, articles_in_category):
    """
    åˆ†æåŒä¸€åˆ†é¡çš„å¤šç¯‡æ–‡ç« ï¼Œç”Ÿæˆçµ±åˆæ‘˜è¦
    å›å‚³: {
        "category": "åˆ†é¡åç¨±",
        "summary": "çµ±åˆæ‘˜è¦",
        "key_points": ["é‡é»1", "é‡é»2", ...],
        "trend_analysis": "è¶¨å‹¢åˆ†æ"
    }
    """
    if not articles_in_category:
        return None
    
    # åˆä½µæ‰€æœ‰æ–‡ç« å…§å®¹
    combined_content = ""
    article_titles = []
    for article in articles_in_category:
        title = article.get('title', 'ç„¡æ¨™é¡Œ')
        content = article.get('content', '')
        article_titles.append(title)
        combined_content += f"\n\nã€{title}ã€‘\n{content}\n"
    
    # é™åˆ¶ç¸½é•·åº¦
    if len(combined_content) > 8000:
        combined_content = combined_content[:8000] + "..."
    
    system_prompt = """
ä½ æ˜¯ä¸€ä½ç¹é«”ä¸­æ–‡çš„è³‡æ·±ç§‘æŠ€ç”¢æ¥­åˆ†æå¸«ã€‚

è«‹åˆ†æä»¥ä¸‹åŒä¸€åˆ†é¡çš„å¤šç¯‡æ–°èæ–‡ç« ï¼Œç”Ÿæˆçµ±åˆåˆ†æã€‚

å›å‚³ JSON æ ¼å¼ï¼š
{
  "category": "åˆ†é¡åç¨±ï¼ˆèˆ‡è¼¸å…¥ç›¸åŒï¼‰",
  "summary": "çµ±åˆæ‘˜è¦ï¼ˆ200-300å­—ï¼Œç¹é«”ä¸­æ–‡ï¼‰",
  "key_points": ["é‡é»1", "é‡é»2", "é‡é»3", "é‡é»4"],
  "trend_analysis": "è¶¨å‹¢åˆ†æèˆ‡ç”¢æ¥­å½±éŸ¿ï¼ˆ150-200å­—ï¼Œç¹é«”ä¸­æ–‡ï¼‰"
}
"""
    
    user_content = f"""
åˆ†é¡ï¼š{category_name}
æ–‡ç« æ•¸é‡ï¼š{len(articles_in_category)}
æ–‡ç« æ¨™é¡Œï¼š{', '.join(article_titles[:10])}  # æœ€å¤šé¡¯ç¤º10å€‹æ¨™é¡Œ

æ–‡ç« å…§å®¹ï¼š
{combined_content}
"""
    
    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_content}
            ],
            temperature=0.4,
            response_format={"type": "json_object"}
        )
        result = json.loads(response.choices[0].message.content)
        result['article_count'] = len(articles_in_category)
        result['article_titles'] = article_titles
        return result
    except Exception as e:
        print(f"âŒ åˆ†é¡åˆ†æå¤±æ•— ({category_name}): {e}")
        return None

def generate_daily_briefing(category_analyses):
    """
    æ ¹æ“šåˆ†é¡åˆ†æçµæœç”Ÿæˆæ¯æ—¥æ±ºç­–æ—¥å ±
    category_analyses: åˆ†é¡åˆ†æçµæœåˆ—è¡¨
    """
    if not category_analyses:
        return "âš ï¸ è³‡æ–™ä¸è¶³ï¼Œç„¡æ³•ç”Ÿæˆæ—¥å ±ã€‚"

    # æ•´ç†è³‡æ–™çµ¦ AI
    input_text = ""
    for cat_analysis in category_analyses:
        category = cat_analysis.get('category', 'æœªåˆ†é¡')
        summary = cat_analysis.get('summary', '')
        key_points = cat_analysis.get('key_points', [])
        trend = cat_analysis.get('trend_analysis', '')
        article_count = cat_analysis.get('article_count', 0)
        
        input_text += f"\n## {category} ({article_count}ç¯‡)\n"
        input_text += f"æ‘˜è¦ï¼š{summary}\n"
        input_text += f"é‡é»ï¼š{', '.join(key_points[:3])}\n"
        input_text += f"è¶¨å‹¢ï¼š{trend}\n"
    
    if len(input_text) > 6000: 
        input_text = input_text[:6000] + "..."

    system_prompt = """
ä½ æ˜¯ä¸€ä½åŠ å¯†è²¨å¹£èˆ‡ç§‘æŠ€ç”¢æ¥­çš„ã€é¦–å¸­ç­–ç•¥å®˜ã€‘ã€‚

è«‹æ ¹æ“šæä¾›çš„åˆ†é¡åˆ†æçµæœï¼Œæ’°å¯«ä¸€ä»½ Markdown æ ¼å¼çš„ã€æ¯æ—¥æ±ºç­–æ—¥å ±ã€‘ã€‚

çµæ§‹å¦‚ä¸‹ï¼š

## ğŸ“Š å¸‚å ´æƒ…ç·’å„€è¡¨æ¿
(æ ¹æ“šæ‰€æœ‰åˆ†é¡çš„å…§å®¹ï¼Œåˆ¤æ–·æ•´é«”å¸‚å ´æ°£æ°›ã€é—œéµç†±è©ã€æŠ•è³‡è€…æƒ…ç·’)

## ğŸŒŠ æ ¸å¿ƒè¶¨å‹¢åˆ†æ
(æ ¹æ“šå„åˆ†é¡çš„è¶¨å‹¢åˆ†æï¼Œæ­¸ç´å‡ºæœ€é‡è¦çš„3-5æ¢æ•…äº‹ç·šï¼Œæ¯æ¢åŒ…å«ï¼š
- è¶¨å‹¢æ¨™é¡Œ
- ç°¡è¦èªªæ˜
- å½±éŸ¿ç¯„åœ)

## ğŸ§­ æ±ºç­–æŒ‡å¼•
(çµ¦é–‹ç™¼è€…èˆ‡æŠ•è³‡è€…çš„å…·é«”å»ºè­°ï¼ŒåŒ…å«ï¼š
- æŠ€è¡“é–‹ç™¼å»ºè­°
- æŠ•è³‡ç­–ç•¥å»ºè­°
- é¢¨éšªæé†’)

## ğŸ“ˆ åˆ†é¡æ‘˜è¦
(ç°¡è¦åˆ—å‡ºå„åˆ†é¡çš„æ ¸å¿ƒè¦é»)
"""

    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": f"ã€åˆ†é¡åˆ†æçµæœã€‘\n{input_text}"}
            ],
            temperature=0.6,
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        return f"âš ï¸ å ±å‘Šç”Ÿæˆå¤±æ•—: {e}"